name: REGISTRIES SEARCH SOLR CD
on:
  push:
    branches:
      - main
    paths:
      - "search-solr/bitnami/**"

  workflow_dispatch:
    inputs:
      environment:
        description: "Environment (dev/test/integration/prod)"
        required: true
        default: "dev"

defaults:
  run:
    shell: bash
    working-directory: ./search-solr

env:
  APP_NAME: "search-solr"
  TAG_NAME: "dev"

jobs:
  search-solr-cd-by-push:
    runs-on: ubuntu-20.04

    permissions:
      contents: "read"
      id-token: "write"

    if: github.event_name == 'push' && github.repository == 'bcgov/registries-search'
    environment:
      name: "dev"

    env:
      PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
      NEW_VERSION: ${{ github.run_id }}${{ github.run_attempt }}
      ZONE: northamerica-northeast1-a
      SEARCH_API_URL: ${{ secrets.SEARCH_API_URL }}

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - id: "auth"
        name: "Authenticate to Google Cloud"
        uses: google-github-actions/auth@v1
        with:
          token_format: "access_token"
          create_credentials_file: true
          activate_credentials_file: true
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER_ID }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
          access_token_lifetime: "3600s"

      - name: Setup - gcloud / gsutil
        uses: google-github-actions/setup-gcloud@v0

      - name: Login to GCP
        run: |
          gcloud auth login --cred-file=${{steps.auth.outputs.credentials_file_path}}

      - name: Copy new solr files to GCP
        run: |
          gsutil -m rsync -R bitnami/ gs://solr-files/bitnami

      - name: Get current solr vm info
        run: |
          gcloud compute instances list --filter name:search-solr --filter status:RUNNING --sort-by NAME --format=json --project=$PROJECT_ID > running_instance.json
          gcloud compute instances list --filter name:search-solr --filter status:TERMINATED --sort-by NAME --format=json --project=$PROJECT_ID > stopped_instance.json
          if [[ $(jq length running_instance.json) != 0 ]]; then
            echo "OLD_INSTANCE=$(jq -r '.[0].name' running_instance.json)" >> $GITHUB_ENV
          fi
          if [[ $(jq length stopped_instance.json) != 0 ]]; then
            echo "OLDEST_INSTANCE=$(jq -r '.[0].name' stopped_instance.json)" >> $GITHUB_ENV
          fi

      - name: Create solr base vm (instance runs startup script to get new solr files)
        run: |
          gcloud compute instances create search-solr-base-$NEW_VERSION --source-instance-template search-solr-base --zone $ZONE --project $PROJECT_ID
          sleep 45s

      - name: Create new solr image
        run: |
          gcloud compute instances stop search-solr-base-$NEW_VERSION --zone $ZONE --project $PROJECT_ID
          gcloud compute images create search-solr-$NEW_VERSION --family search-solr --source-disk search-solr-base-$NEW_VERSION --source-disk-zone $ZONE --storage-location northamerica-northeast1 --project $PROJECT_ID

      - name: Create new solr vm
        run: |
          gcloud compute instances create search-solr-$TAG_NAME-$NEW_VERSION --source-instance-template search-solr-$TAG_NAME --zone $ZONE --project $PROJECT_ID
          gcloud compute instance-groups unmanaged add-instances search-solr-preload-grp-$TAG_NAME --zone=$ZONE --instances=search-solr-$TAG_NAME-$NEW_VERSION

      - name: Login Openshift
        run: |
          oc login --server=${{secrets.OPENSHIFT4_LOGIN_REGISTRY}} --token=${{secrets.OPENSHIFT4_SA_TOKEN}}

      - name: Preload new solr vm index
        run: |
          oc -n ${{secrets.OPENSHIFT4_REPOSITORY}}-$TAG_NAME process -f solr-preload-jobs/preload_template.yaml -p ENV=$TAG_NAME

      - name: Add new solr vm to active load balancer
        run: |
          gcloud compute instance-groups unmanaged remove-instances search-solr-preload-grp-$TAG_NAME --zone=$ZONE --instances=search-solr-$TAG_NAME-$NEW_VERSION
          gcloud compute instance-groups unmanaged add-instances search-solr-active-grp-$TAG_NAME --zone=$ZONE --instances=search-solr-$TAG_NAME-$NEW_VERSION

      - name: Cleanup (stop perviously running instances and delete previously stopped instances)
        run: |
          if [ -n $OLD_INSTANCE ]; then
            gcloud compute instances stop $OLD_INSTANCE --zone=$ZONE --project $PROJECT_ID
          fi
          if [ -n $OLDEST_INSTANCE ]; then
            gcloud compute instances delete $OLDEST_INSTANCE --zone=$ZONE --project $PROJECT_ID
          fi
          gcloud compute instances delete search-solr-base-$NEW_VERSION --zone $ZONE --project $PROJECT_ID

      - name: Resync (catch any missed updates that happened during the fresh import)
        run: |
          curl -X POST $SEARCH_API_URL/internal/solr/update/resync -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{"offsetMinutes": 60}'

  search-solr-cd-by-dispatch:
    runs-on: ubuntu-20.04

    permissions:
      contents: "read"
      id-token: "write"

    if: github.event_name == 'workflow_dispatch' && github.repository == 'bcgov/registries-search'
    environment:
      name: "${{ github.event.inputs.environment }}"

    env:
      PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
      NEW_VERSION: ${{ github.run_id }}${{ github.run_attempt }}
      SEARCH_API_URL: ${{ secrets.SEARCH_API_URL }}
      ZONE: northamerica-northeast1-a

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Set env by input
        run: |
          echo "TAG_NAME=${{ github.event.inputs.environment }}" >> $GITHUB_ENV

      - id: "auth"
        name: "Authenticate to Google Cloud"
        uses: google-github-actions/auth@v1
        with:
          token_format: "access_token"
          create_credentials_file: true
          activate_credentials_file: true
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER_ID }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
          access_token_lifetime: "3600s"

      - name: Setup - gcloud / gsutil
        uses: google-github-actions/setup-gcloud@v0

      - name: Login to GCP
        run: |
          gcloud auth login --cred-file=${{steps.auth.outputs.credentials_file_path}}

      - name: Copy new solr files to GCP
        if: ${{ env.TAG_NAME == 'dev' }}
        run: |
          gsutil -m rsync -R bitnami/ gs://solr-files/bitnami

      - name: Get current solr vm info
        run: |
          gcloud compute instances list --filter name:search-solr-$TAG_NAME --filter status:RUNNING --sort-by NAME --format=json --project=$PROJECT_ID > running_instance.json
          gcloud compute instances list --filter name:search-solr-$TAG_NAME --filter status:TERMINATED --sort-by NAME --format=json --project=$PROJECT_ID > stopped_instance.json
          if [[ $(jq length running_instance.json) != 0 ]]; then
            echo "OLD_INSTANCE=$(jq -r '.[0].name' running_instance.json)" >> $GITHUB_ENV
          fi
          if [[ $(jq length stopped_instance.json) != 0 ]]; then
            echo "OLDEST_INSTANCE=$(jq -r '.[0].name' stopped_instance.json)" >> $GITHUB_ENV
          fi

      - name: Create solr base vm (instance runs startup script to get new solr files)
        if: ${{ env.TAG_NAME == 'dev' }}
        run: |
          gcloud compute instances create search-solr-base-$NEW_VERSION --source-instance-template search-solr-base --zone $ZONE --project $PROJECT_ID
          sleep 30s

      - name: Create new solr image
        if: ${{ env.TAG_NAME == 'dev' }}
        run: |
          gcloud compute instances stop search-solr-base-$NEW_VERSION --zone $ZONE --project $PROJECT_ID
          gcloud compute images create search-solr-$NEW_VERSION --family search-solr --source-disk search-solr-base-$NEW_VERSION --source-disk-zone $ZONE --project $PROJECT_ID

      - name: Create new solr vm
        run: |
          gcloud compute instances create search-solr-$TAG_NAME-$NEW_VERSION --source-instance-template search-solr-$TAG_NAME --zone $ZONE --project $PROJECT_ID
          gcloud compute instance-groups unmanaged add-instances search-solr-preload-grp-$TAG_NAME --zone=$ZONE --instances=search-solr-$TAG_NAME-$NEW_VERSION

      - name: Login Openshift
        run: |
          oc login --server=${{secrets.OPENSHIFT4_LOGIN_REGISTRY}} --token=${{secrets.OPENSHIFT4_SA_TOKEN}}

      - name: Preload new solr vm index
        if: ${{ env.TAG_NAME != 'integration' }}
        run: |
          oc -n ${{secrets.OPENSHIFT4_REPOSITORY}}-$TAG_NAME process -f solr-preload-jobs/preload_template.yaml -p ENV=$TAG_NAME

      - name: Preload new solr vm index in sandbox
        if: ${{ env.TAG_NAME == 'integration' }}
        run: |
          oc -n ${{secrets.OPENSHIFT4_REPOSITORY}}-prod process -f solr-preload-jobs/integration_preload_template.yaml -p PRELOAD_URL=${{secrets.INTEGRATION_PRELOAD_URL}}

      - name: Add new solr vm to active load balancer
        run: |
          gcloud compute instance-groups unmanaged remove-instances search-solr-preload-grp-$TAG_NAME --zone=$ZONE --instances=search-solr-$TAG_NAME-$NEW_VERSION
          gcloud compute instance-groups unmanaged add-instances search-solr-active-grp-$TAG_NAME --zone=$ZONE --instances=search-solr-$TAG_NAME-$NEW_VERSION

      - name: Cleanup (stop perviously running instances and delete previously stopped instances)
        run: |
          if [ -n $OLD_INSTANCE ]; then
            gcloud compute instances stop $OLD_INSTANCE --zone=$ZONE --project $PROJECT_ID
          fi
          if [ -n $OLDEST_INSTANCE ]; then
            gcloud compute instances delete $OLDEST_INSTANCE --zone=$ZONE --project $PROJECT_ID
          fi
          gcloud compute instances delete search-solr-base-$NEW_VERSION --zone $ZONE --project $PROJECT_ID

      - name: Resync (catch any missed updates that happened during the fresh import)
        run: |
          curl -X POST $SEARCH_API_URL/internal/solr/update/resync -H 'Content-Type: application/json' -H 'Accept: application/json' -d '{"offsetMinutes": 60}'
